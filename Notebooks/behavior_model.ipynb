{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from simulation_utils import *\n",
    "from behavior_model_utils import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Behavior Model in Single-Player Grid 6x6 Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanNN(\n",
       "  (fc1): Linear(in_features=144, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (fc4): Linear(in_features=1024, out_features=4, bias=True)\n",
       "  (sm): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_size = 6\n",
    "search_depth = 10\n",
    "\n",
    "# Load pre-trained human behavior model for 6x6 grid\n",
    "model = torch.load('../behavior-models/human_model_grid6.pt', map_location=torch.device('cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action history is: [2, 2, 2, 1, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "seed_number = 42\n",
    "random.seed(seed_number)\n",
    "np.random.seed(seed_number)\n",
    "torch.manual_seed(seed_number)\n",
    "\n",
    "# Randomly choose the number of blocked positions based on the grid size\n",
    "num_blocked_positions = random.choice(range(grid_size * 2))\n",
    "\n",
    "# Randomize positions for goal, special reward, blocked positions, and start position\n",
    "new_goal_positions, new_special_reward_positions, new_blocked_positions, start_pos = randomize_pos(\n",
    "    grid_size, 1, 0, num_blocked_positions\n",
    ")\n",
    "\n",
    "# Encode the grid design into a numpy array\n",
    "layout0 = encode_grid_design_numpy(\n",
    "    n=grid_size, \n",
    "    goal_positions=new_goal_positions, \n",
    "    blocked_positions=new_blocked_positions, \n",
    "    start_pos=start_pos\n",
    ")\n",
    "\n",
    "# Build the map with the given layout and start position\n",
    "dis = build_map(layout0, start_pos=start_pos)\n",
    "\n",
    "# Check if the distance to the goal is too large (i.e., invalid environment)\n",
    "if dis[new_goal_positions[0][0], new_goal_positions[0][1]] >= 50:\n",
    "    print('Invalid environment')\n",
    "    # Here you might want to handle invalid environments or recalculate\n",
    "\n",
    "# Generate all possible layouts\n",
    "all_layout = generate_all_layout(layout0, grid_size=grid_size)\n",
    "\n",
    "# Predict valid moves and human behavior\n",
    "valids, human_pred = move_pred(all_layout, model, grid_size=grid_size)\n",
    "\n",
    "# Get the goal position from the layout\n",
    "goal_pos1 = tuple(np.argwhere(layout0[3, :, :])[0])\n",
    "\n",
    "# Compute the human path using search with preset look ahead depth\n",
    "move, wcd = compute_human_path_searchk_preset(\n",
    "    layout0, all_layout, valids, model, look_ahead=search_depth, grid_size=grid_size, goal_pos=goal_pos1\n",
    ")\n",
    "\n",
    "# Print the action history\n",
    "print('Action history is:', move)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Behavior Model in Two-Player Grid 8x8 Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanNN(\n",
       "  (fc1): Linear(in_features=160, out_features=4096, bias=True)\n",
       "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (fc3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (fc4): Linear(in_features=4096, out_features=5, bias=True)\n",
       "  (sm): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_size = 8\n",
    "search_depth = 10\n",
    "\n",
    "model = torch.load('../behavior-models/human_model_grid8.pt', map_location=torch.device('cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experiment map layout for two-player grid 8x8 environments\n",
    "with open('../experiment3/map_layout_experiment3.json', 'r') as json_file:\n",
    "    experiment3_layouts = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1 [(3, 3), (1, 0)]\n",
      "3 2 2 [(3, 2), (1, 1)]\n",
      "3 2 3 [(3, 1), (1, 2)]\n",
      "3 2 4 [(3, 0), (1, 3)]\n",
      "0 2 5 [(3, 0), (1, 4)]\n",
      "0 2 6 [(3, 0), (1, 5)]\n",
      "0 2 7 [(3, 0), (1, 6)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, True, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a specific map layout for the experiment\n",
    "idx = 26\n",
    "seq = experiment3_layouts[idx]\n",
    "block_pos, start_pos, goal_pos, _ = seq\n",
    "\n",
    "# Convert positions to tuples\n",
    "start_pos = [tuple(pos) for pos in start_pos]\n",
    "goal_pos = [tuple(pos) for pos in goal_pos]\n",
    "\n",
    "# Initialize the environment with the given parameters\n",
    "env = navigation_share_env(grid_size, start_pos, goal_pos, block_pos)\n",
    "env.reset()\n",
    "\n",
    "# Set behavior sampling method\n",
    "random_behavior = False  # Sample based on the probability\n",
    "\n",
    "# Initialize rewards and hit tracking\n",
    "rewards = 0\n",
    "hits = [False, False]\n",
    "\n",
    "# Initialize done flag and step counter\n",
    "done = False\n",
    "counts = 0\n",
    "max_step = 30  # Maximum steps allowed in the experiment\n",
    "\n",
    "# Run the experiment loop\n",
    "while not done and counts <= max_step:\n",
    "    # Get the current layout for both players\n",
    "    s = get_both_layout(env)\n",
    "    counts += 1\n",
    "    \n",
    "    # Get action probabilities from the model for both players\n",
    "    prob1 = model.forward_beta(torch.tensor(s[0]).reshape(1, -1), beta=0.03).detach().numpy()[0]\n",
    "    prob2 = model.forward_beta(torch.tensor(s[1]).reshape(1, -1), beta=0.03).detach().numpy()[0]\n",
    "    \n",
    "    # Select actions with the highest probabilities\n",
    "    a1, a2 = int(np.argmax(prob1)), int(np.argmax(prob2))\n",
    "    \n",
    "    # Take a step in the environment with the selected actions\n",
    "    rewards, done = env.step([int(a1), int(a2)])\n",
    "    \n",
    "    # Print the actions and current positions\n",
    "    print(a1, a2, counts, env.cur_pos)\n",
    "\n",
    "# Output final rewards, done flag, and step count\n",
    "rewards, done, counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
